{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Haunted Mansion\n",
    "\n",
    "Welcome to the haunted mansion, a 3 dimensional array for an agent to learn to navigate. The agent will start out in position (0,0,0) and it will try to exit at point (size,size,size). I will start with a relatively small size and adjust it if needed.\n",
    "\n",
    "### The agent will encounter a few things throughout its journey through the haunted mansion. \n",
    "- It will encounter monsters sporadically\n",
    "    - There will be \"hot spots\", maybe 3x3x3 areas where monsters are likely to spawn, and in the center of themis lots of treasure. \n",
    "    \n",
    "- It will encounter treasure throughout its adventure\n",
    "    - The treasure will be the *value* metric of the agent. The immediate reward will be the steps that it takes. \n",
    "    \n",
    "\n",
    "### Two policies\n",
    "1. We'll try to design a policy where the agent wants to get *out* of the haunted mansion as quickly as it can. \n",
    "\n",
    "2. We'll also try a \"hero\" policy where it collects as much treasure as it can and gains strength (through slaying monsters) \n",
    "\n",
    "### Strength\n",
    "The agent will have a strength that determines whether it will die or win against a given monster. The monsters will spawn probabilistically in a given \"hot spot\" and they will have strengths as well. If the agent wins (ie. agent strength > monster strength), it gains strength. If they are equally matched, it is a coin flip. \n",
    "\n",
    "### Treasure \n",
    "Treasure will be the value function of the environment. There will be more treasure available inside of the monster zones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's first set up the environment and the agent\n",
    "\n",
    "# importing scipy.stats for normal distribution for monster spawning probabilities\n",
    "import scipy.stats\n",
    "\n",
    "tre = 0\n",
    "mon = 1\n",
    "\n",
    "class Environment: \n",
    "    def __init__(self, size, hotspots=[(3,3,3,3)]):\n",
    "        self.size = size\n",
    "        self.hotspot_prob_cache3x3 = self.gen_hotspot_prob_matrix(3)\n",
    "        self.hotspot_prob_cache5x5 = self.gen_hotspot_prob_matrix(5)\n",
    "        self.hotspots = hotspots\n",
    "        self.map = self.generate_map(size, hotspots)\n",
    "        \n",
    "    def generate_map(self, map_size, hotspots):\n",
    "        env = np.empty(shape=(map_size, map_size, map_size, 2))\n",
    "        \n",
    "        for i in range(map_size):\n",
    "            for j in range(map_size):\n",
    "                for k in range(map_size):\n",
    "                    treasure = 0\n",
    "                    monster = 0\n",
    "                    env[i,j,k] = [treasure, monster]\n",
    "                    \n",
    "        for (x, y, z, s) in hotspots:\n",
    "            r = s // 2\n",
    "            env[x-r:x+r+1, y-r:y+r+1, z-r:z+r+1] = self.populate_hotspot((x, y, z), s)\n",
    "        \n",
    "        return env\n",
    "            \n",
    "            \n",
    "    def populate_hotspot(self, loc, hotspot_size):\n",
    "        r = hotspot_size // 2\n",
    "        x, y, z = loc\n",
    "        \n",
    "        hotspot = np.empty(shape=(hotspot_size, hotspot_size, hotspot_size, 2))\n",
    "        \n",
    "        for i in range(hotspot_size):\n",
    "            for j in range(hotspot_size):\n",
    "                for k in range(hotspot_size):\n",
    "                    # treasure is multiplied by the probability of a monster\n",
    "                    if hotspot_size == 3:\n",
    "                        treasure = self.hotspot_prob_cache3x3[i,j,k] * 50\n",
    "                    elif hotspot_size == 5:\n",
    "                        treasure = self.hotspot_prob_cache5x5[i,j,k] * 50\n",
    "                    monster = np.random.randint(8)+1       # random strength 1 to 8\n",
    "                    hotspot[i,j,k] = [treasure, monster]\n",
    "        \n",
    "        return hotspot\n",
    "    \n",
    "    \n",
    "    def regenerate_hotspots(self):\n",
    "        for (x, y, z, s) in self.hotspots:\n",
    "            r = s // 2\n",
    "            self.map[x-r:x+r+1, y-r:y+r+1, z-r:z+r+1] = self.populate_hotspot((x, y, z), s)\n",
    "            \n",
    "        \n",
    "        \n",
    "    \n",
    "    # the distance from the center of the hotspot determines\n",
    "    # how likely a monster is to spawn there - there is always\n",
    "    # a monster in the center\n",
    "    def gen_hotspot_prob_matrix(self, size):\n",
    "        \n",
    "        arr = np.zeros((size,size,size))\n",
    "        mid = (size//2, size//2, size//2)\n",
    "        xh, yh, zh = mid\n",
    "        \n",
    "        # generate probabilities at given relative locations\n",
    "        for i in range(size):\n",
    "            for j in range(size):\n",
    "                for k in range(size):\n",
    "                    dist = np.sqrt((i-xh)**2 + (j-yh)**2 + (k-zh)**2)\n",
    "                    gen_prob = scipy.stats.norm(0, size/2).cdf(-dist)\n",
    "                    arr[i,j,k] = gen_prob\n",
    "        \n",
    "        # always a monster in the center!\n",
    "        arr[mid] = 1\n",
    "                    \n",
    "        return arr\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.12410654 0.17288929 0.12410654]\n",
      "  [0.17288929 0.25249254 0.17288929]\n",
      "  [0.12410654 0.17288929 0.12410654]]\n",
      "\n",
      " [[0.17288929 0.25249254 0.17288929]\n",
      "  [0.25249254 1.         0.25249254]\n",
      "  [0.17288929 0.25249254 0.17288929]]\n",
      "\n",
      " [[0.12410654 0.17288929 0.12410654]\n",
      "  [0.17288929 0.25249254 0.17288929]\n",
      "  [0.12410654 0.17288929 0.12410654]]]\n"
     ]
    }
   ],
   "source": [
    "env = Environment(6, hotspots=[(3,3,3,3)])\n",
    "\n",
    "# here's the probability of a monster spawning in a given 3x3x3 hotspot\n",
    "# note there will always be a monster in the middle of the hotspot\n",
    "# (this is where the most treasure is!)\n",
    "print(env.hotspot_prob_cache3x3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 7. 8. 1. 0.]\n",
      "  [0. 0. 7. 8. 3. 0.]\n",
      "  [0. 0. 1. 7. 2. 0.]\n",
      "  [0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 7. 8. 4. 0.]\n",
      "  [0. 0. 4. 4. 8. 0.]\n",
      "  [0. 0. 1. 6. 4. 0.]\n",
      "  [0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 4. 2. 7. 0.]\n",
      "  [0. 0. 2. 6. 6. 0.]\n",
      "  [0. 0. 4. 1. 1. 0.]\n",
      "  [0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "# and here we can see the \"hot spot\" on a small map\n",
    "# the numbers are the strengths of the monsters in that area\n",
    "print(env.map[:,:,:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent\n",
    "Now we have to design an agent.\n",
    "\n",
    "An agent has actions that respond to the environment. The actions here will be up, down, left, right, forward, and backward. This first Agent we're going to try to get him to simply get to the exit as fast as possible. This policy should be relatively easy to implement - we're going to just take the distance formula from the position the agent is at, and if it steps in the direction of the exit, we reward it\n",
    "\n",
    "What will be interesting is when it encounters a hotspot and gets negative reward for dying, will it tend to avoid the area? \n",
    "\n",
    "### Bellman Equation\n",
    "The Bellman equation, used to update the policies at each step:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, environment):\n",
    "        self.actions = [0,1,2,3,4,5]\n",
    "        self.strength = 2\n",
    "        self.treasure = 0.0\n",
    "        self.environment = environment\n",
    "        self.env_size = environment.size\n",
    "        self.final_pos = (self.environment.size-1, self.environment.size-1, self.environment.size-1)\n",
    "        self.q_table = self.make_q_table(environment)\n",
    "    \n",
    "    def act(self, position):\n",
    "        x, y, z = position\n",
    "        \n",
    "        # might have to change this to pick randomly\n",
    "        action = self.choose_action(position)\n",
    "        \n",
    "        # update position\n",
    "        if action == 0: # up\n",
    "            new_pos = (x,y,z+1)\n",
    "        elif action == 1: # down\n",
    "            new_pos = (x,y,z-1)\n",
    "        elif action == 2: # left\n",
    "            new_pos = (x-1,y,z)\n",
    "        elif action == 3: # right\n",
    "            new_pos = (x+1,y,z)\n",
    "        elif action == 4: # forward\n",
    "            new_pos = (x,y+1,z)\n",
    "        elif action == 5: # backward\n",
    "            new_pos = (x,y-1,z)\n",
    "        \n",
    "        new_x, new_y, new_z = new_pos\n",
    "        \n",
    "        # check if agent went off the map\n",
    "        if new_x < 0 or new_y < 0 or new_z < 0 or new_x >= self.env_size or new_y >= self.env_size or new_z >= self.env_size:\n",
    "            reward = -5\n",
    "            new_pos = position\n",
    "            return action, new_pos, reward, False\n",
    "        \n",
    "        reward = 1\n",
    "        \n",
    "        # check for monsters and simulate interaction \n",
    "        monster = self.environment.map[new_pos][1]\n",
    "        if monster:\n",
    "            if self.strength > monster or (self.strength == monster and np.random.uniform() <= 0.5):\n",
    "                self.treasure += self.environment.map[new_pos][0]\n",
    "                self.strength += 1\n",
    "            else:\n",
    "                reward = -5\n",
    "                return action, new_pos, reward, True\n",
    "        \n",
    "        return action, new_pos, reward, False\n",
    "            \n",
    "        \n",
    "        # Function for choosing the action for the agent\n",
    "    def choose_action(self, position):\n",
    "\n",
    "        # Selection of the action - 90 % according to the epsilon == 0.9\n",
    "        # Choosing the best action\n",
    "        if np.random.uniform() < 0.9 and not (np.argmin(self.q_table[position]) == np.argmax(self.q_table[position])):\n",
    "            state_action = self.q_table[position]\n",
    "            action = np.argmax(state_action)\n",
    "        else:\n",
    "            # Choosing random action - left 10 % for choosing randomly\n",
    "            action = np.random.choice(self.actions)\n",
    "        \n",
    "        return action\n",
    "\n",
    "    \n",
    "    \n",
    "    def learn(self, episodes=1000, learning_rate=0.9):\n",
    "        \n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        # reward decay\n",
    "        self.gamma = 0.1\n",
    "        \n",
    "        # reset q table\n",
    "        self.q_table = self.make_q_table(self.environment)\n",
    "        \n",
    "        for e in range(episodes):\n",
    "            position = (0,0,0)\n",
    "            self.strength = 0\n",
    "            if e % 100 == 0:\n",
    "                print('episode {}'.format(e))\n",
    "            while position != self.final_pos:\n",
    "                action, new_pos, reward, dead = self.act(position)\n",
    "                if new_pos == self.final_pos:\n",
    "                    self.q_table[position][action] += 50\n",
    "                else:\n",
    "                    self.q_table[position][action] += learning_rate * ((reward + self.gamma * max(self.q_table[new_pos]) - self.q_table[position][action]))\n",
    "                # print(learning_rate, reward, self.gamma, max(self.q_table[new_pos]))\n",
    "                if dead:\n",
    "                    position = (0,0,0)\n",
    "                    break\n",
    "                \n",
    "                position = new_pos\n",
    "                \n",
    "    def run(self):\n",
    "        xy_run = np.zeros((self.env_size, self.env_size))\n",
    "        xz_run = np.zeros((self.env_size, self.env_size))\n",
    "        yz_run = np.zeros((self.env_size, self.env_size))\n",
    "        \n",
    "        xy_run[0,0] = 1\n",
    "        xz_run[0,0] = 1\n",
    "        yz_run[0,0] = 1\n",
    "        \n",
    "        position = (0,0,0)\n",
    "\n",
    "        while position != self.final_pos:\n",
    "            action, new_pos, reward, dead = self.act(position)\n",
    "            # self.q_table[position][action] += reward\n",
    "            \n",
    "            x, y, z = new_pos\n",
    "            xy_run[x,y] = 1\n",
    "            xz_run[x,z] = 1\n",
    "            yz_run[y,z] = 1\n",
    "\n",
    "            if dead:\n",
    "                position = (0,0,0)\n",
    "                break\n",
    "                \n",
    "            position = new_pos\n",
    "        \n",
    "        return xy_run, xz_run, yz_run\n",
    "            \n",
    "    \n",
    "    # the q table is a dictionary containing the reward at each \n",
    "    # position in the environment\n",
    "    def make_q_table(self, environment):\n",
    "        \n",
    "        q_table = dict()\n",
    "        width, height, depth, size = environment.map.shape\n",
    "        \n",
    "        for i in range(width):\n",
    "            for j in range(height):\n",
    "                for k in range(depth):\n",
    "                    # index:action\n",
    "                    # 0:up, 1:down, 2:left, 3:right, 4:fwd, 5:bkwd\n",
    "                    q_table[(i, j, k)] = [0,0,0,0,0,0]\n",
    "        \n",
    "        return q_table\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 0\n",
      "episode 100\n",
      "episode 200\n",
      "episode 300\n",
      "episode 400\n",
      "episode 500\n",
      "episode 600\n",
      "episode 700\n",
      "episode 800\n",
      "episode 900\n"
     ]
    }
   ],
   "source": [
    "learner6x6 = Agent(env)\n",
    "learner6x6.learn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(0, 0, 0): [1.1111111111111112, -4.888888888888889, -4.888888888888889, 1.1111111111111112, 1.1111111111111112, -4.888888888888889], (0, 0, 1): [1.111111111111111, 1.1111111111, -4.8888888884, 1.1111111111111112, 1.111111111, -4.888888888888889], (0, 0, 2): [1.1111111111111112, 0, -4.4, 0, 1.0, -4.4], (0, 0, 3): [1.1111111111110001, 1.1111, -4.888884, 1.1111111111111112, 1.111111111, -4.888888884000001], (0, 0, 4): [1.1111111111111112, 1.1111111111111112, -4.888888888888889, 1.1111111111111112, 1.1111111111111112, -4.888888888888889], (0, 0, 5): [-4.888888888888889, 1.1111111111111112, -4.888888888888889, 1.1111111111111112, 1.1111111111111112, -4.888888888888889], (0, 1, 0): [1.0, 0, -4.840000000000002, 1.1111111111111112, 1.109, 0], (0, 1, 1): [1.1, 1.111097999999999, -4.88884, 1.1111111111111112, 1.0999999999897998, 1.11], (0, 1, 2): [1.1111111111109575, 1.1111111111109, -4.88888888884, 1.1111111, 1.1111111111111112, 1.1111111111048095], (0, 1, 3): [0, 0, -4.8400000010211315, 1.1111111111111112, 0, 1.0], (0, 1, 4): [1.1111111111111112, 1.1, -4.888400002981063, 1.11111, 1.11, 1.1109999], (0, 1, 5): [-4.88884, 1.11, -4.888884, 1.1111111111111112, 0, 1.11], (0, 2, 0): [1.1111109867395847, -4.840000000000001, -4.840000000000001, 1.11, 1.1111111111111112, 1.11], (0, 2, 1): [1.0, 0, -4.4, 1.1111111111111112, 0.9999, 0], (0, 2, 2): [1.1111111111111112, 1.1111111111111112, -4.888888888888889, 1.1111111111111112, 1.1111111111111112, 1.1111111111111112], (0, 2, 3): [1.1111111111111112, 1.1111111111111112, -4.888888888888401, 1.1111111111111112, 1.1111111111111112, 1.111111111], (0, 2, 4): [1.1111111111, 1.11, -4.888884, 1.1111111111111112, 1.1111111111, 1.1111111109961258], (0, 2, 5): [-4.888888885, 1.1111090000000001, -4.888888840000001, 1.1111111111111112, 1.11111111111, 1.111110999989099], (0, 3, 0): [0.99999, -4.888400000000001, -4.884, 1.11, 1.1110999989999901, 1.1111111111111112], (0, 3, 1): [0, 0, 0, 1.1111, 0, 0], (0, 3, 2): [0, 0.9990000000000001, -4.840000000001, 0, 0, 1.1111111111111112], (0, 3, 3): [1.1111, 1.09999999999999, -4.840000000000001, 1.1, 1.1, 1.1111111111111112], (0, 3, 4): [1.1111111111111112, 1.1111111111111112, -4.888888888888889, 1.1111111111111112, 1.1111111111111112, 1.1111111111111112], (0, 3, 5): [-4.888888888888889, 1.1111111111111112, -4.888888888888889, 1.1111111111111112, 1.1111111111111112, 1.1111111111111112], (0, 4, 0): [0.9999999999999811, 0, -4.40001, 0, 1.1111111111111112, 0], (0, 4, 1): [0, 0, 0, 1.1111111111111112, 0, 0.9900000000000001], (0, 4, 2): [1.0, 1.1111111111111112, -4.4, 0, 1.111, 0], (0, 4, 3): [1.1111111, 1.1110999999300037, -4.4, 1.111, 1.1111111111111112, 1.1110999999999993], (0, 4, 4): [1.1111111111111112, 1.1111111111111112, -4.888888888888889, 1.1111111111111112, 1.1111111111111112, 1.1111111111111112], (0, 4, 5): [-4.888888888888889, 1.1111111111111112, -4.888888888888889, 1.1111111111111112, 1.1111111111111112, 1.1111111111111112], (0, 5, 0): [1.1111111111111112, -4.888888840000001, -4.88888888888884, 1.1111111111110001, -4.888400000000001, 1.1111111110787988], (0, 5, 1): [1.1111111111111112, 1.1111, -4.88884, 1.1111111111111112, -4.8888888885, 1.11110999999981], (0, 5, 2): [1.1111111111111112, 1.11111111, -4.8888888888885, 1.1111111111111098, -4.888888840000007, 1.1111111098170001], (0, 5, 3): [1.1111111111111112, 1.1111111111111112, -4.888888888888889, 1.1111111111111112, -4.888888888888889, 1.1111111111111112], (0, 5, 4): [1.1111111111111112, 1.1111111111111112, -4.888888888888889, 1.1111111111111112, -4.888888888888889, 1.1111111111111112], (0, 5, 5): [-4.888888888888889, 1.1111111111111112, -4.888888888888889, 1.1111111111111112, -4.888888888888889, 1.1111111111111112], (1, 0, 0): [1.1111111111111112, -4.840000000000001, 1.0, 0, 0, -4.884], (1, 0, 1): [1.1111111111111112, 1.1111111111111112, 1.1111111111111112, 1.1111111111111112, 1.1111111111111112, -4.888888888888889], (1, 0, 2): [1.1111111111111112, 1.1111111, 1.11, 1.11111, 1.1111, -4.8888850001], (1, 0, 3): [1.1111111111111112, 1.1111111111111112, 1.1111111111111112, 1.1111111111111112, 1.1111111111111112, -4.888888888888889], (1, 0, 4): [1.1111111111111112, 1.1111111111111112, 1.1111111111111112, 1.1111111111111112, 1.1111111111111112, -4.888888888888889], (1, 0, 5): [-4.888888888888889, 1.1111111111111112, 1.1111111111111112, 1.1111111111111112, 1.1111111111111112, -4.888888888888889], (1, 1, 0): [1.1111111111111112, -4.888888888888889, 1.1111111111080891, 1.1111111111111112, 1.1111111111111112, 1.1111111111111112], (1, 1, 1): [1.1111111111111112, 1.1111111111111112, 1.1111111111111112, 1.1111111111111112, 1.1111111111111112, 1.1111111111111112], (1, 1, 2): [1.11111, 1.1, 1.111, 1.111, 1.1111111111111112, 1.11111111110999], (1, 1, 3): [1.1111111111, 1.1111111111111112, 1.1111111111111112, 1.1111111111111112, 1.1111111111, 1.1111111111111112], (1, 1, 4): [1.1111111111111112, 1.1111111111111112, 1.1111111111111112, 1.1111111111111112, 1.1111111111111112, 1.1111111111111112], (1, 1, 5): [-4.888888888888401, 1.1111111111111112, 1.11111111111111, 1.1111111111111112, 1.1111111111111112, 1.1111111111111112], (1, 2, 0): [1.111111111, -4.888888400000001, 1.1111110999999998, 1.1111094, 1.1111111111111112, 1.111111], (1, 2, 1): [1.11111, 1.1111111111111112, 1.1111110999999898, 1.1111110767, 1.1111111111098968, 1.1111111], (1, 2, 2): [1.1111111, 1.1111111111111112, 1.1111111, -4.95, 1.111089699627209, 1.1109999291419779], (1, 2, 3): [1.1111111111111112, 1.1109999805614745, 1.11111111, -4.999995, 1.1111110999999991, 1.1098829000000001], (1, 2, 4): [1.1111111111111112, 1.1111111111111112, 1.1111111111111112, -5.0, 1.1111111111111112, 1.1111111111111112], (1, 2, 5): [-4.888888888888889, 1.1111111111111112, 1.1111111111111112, 1.1111111111111112, 1.1111111111111112, 1.1111111111111112], (1, 3, 0): [1.111111111, -4.8888888840361, 1.1111111111, 1.1110689, 1.1111111111111112, 1.1111111], (1, 3, 1): [0.9999999999899909, 1.1111111111111112, 0.9, 1.0999999999997987, 0, 0], (1, 3, 2): [1.1111111110999898, 0, 0.9999999999999999, 0, 0, 0], (1, 3, 3): [1.1111111111111112, 1.1109989969890912, 1.11, -4.999995, 1.111, 1.0], (1, 3, 4): [1.1111111111111112, 1.1111111111111112, 1.1111111111111112, -5.0, 1.1111111111111112, 1.1111111111111112], (1, 3, 5): [-4.888888888888889, 1.1111111111111112, 1.1111111111111112, 1.1111111111111112, 1.1111111111111112, 1.1111111111111112], (1, 4, 0): [1.111111, -4.888888888888404, 1.111109989979, 1.1111111109, 1.1111111111111112, 1.1111111111110001], (1, 4, 1): [1.111110869296269, 1.1111111099999993, 1.11111111111111, 1.1111111111109981, 1.1111111111111112, 1.11111111111111], (1, 4, 2): [1.0, 1.0, 1.1111111111111112, 0, 1.0, 1.0989989999091], (1, 4, 3): [1.1111111111111112, 1.1111111088861023, 1.111111099999, -4.9995, 1.1110999999998097, 1.111110999999999], (1, 4, 4): [1.1111111111111112, 1.1111111111111112, 1.1111111111111112, -5.0, 1.1111111111111112, 1.1111111111111112], (1, 4, 5): [-4.888888888888889, 1.1111111111111112, 1.1111111111111112, 1.1111111111111112, 1.1111111111111112, 1.1111111111111112], (1, 5, 0): [1.1111111111110001, -4.888888884, 1.1111111111111112, 1.111111111099978, -4.888888840000001, 1.111111111], (1, 5, 1): [1.1111111111111112, 1.1111111111111112, 1.1111111111111112, 1.1111111111111112, -4.888888888888889, 1.1111111111111112], (1, 5, 2): [1.1111111111111112, 1.1111111111111112, 1.1111111111111112, 1.1111111111111112, -4.888888888888889, 1.1111111111111112], (1, 5, 3): [1.1111111111111112, 1.1111111111111112, 1.1111111111111112, 1.1111111111111112, -4.888888888888889, 1.1111111111111112], (1, 5, 4): [1.1111111111111112, 1.1111111111111112, 1.1111111111111112, 1.1111111111111112, -4.888888888888889, 1.1111111111111112], (1, 5, 5): [-4.888888888888889, 1.1111111111111112, 1.1111111111111112, 1.1111111111111112, -4.888888888888889, 1.1111111111111112], (2, 0, 0): [1.1111, 0, 0, 0, 0, -4.5], (2, 0, 1): [1.1111111111111112, 1.11105, 1.11111, 1.1070000000000002, 1.11111, -4.840000000000001], (2, 0, 2): [1.1111111111111112, 1.1111111099997988, 1.1111111111, 1.1111111110259253, 1.1111109993141, -4.888888884], (2, 0, 3): [1.1111111111111112, 1.11111111111111, 1.1111111111111112, 1.1111111111110001, 1.1111111111111112, -4.888888888888401], (2, 0, 4): [1.1111111111111112, 1.1111111111111112, 1.1111111111111112, 1.1111111111111112, 1.1111111111111112, -4.888888888888889], (2, 0, 5): [-4.888888888888884, 1.11111111, 1.1111111111, 1.1111111111111112, 1.1111111111111112, -4.888888884], (2, 1, 0): [0, 0, 1.1111111111111112, 0.9, 1.0899990000000002, 0], (2, 1, 1): [1.1111111111111112, 1.111, 1.11111, 1.1088, 1.110898989, 1.1110900000000001], (2, 1, 2): [1.111, 1.11, 1.111, 1.109998899999999, -4.995, 1.1111111111111112], (2, 1, 3): [1.1111111111111112, 1.1111111111111112, 1.1111111111111112, 1.1111111111111112, -5.0, 1.1111111111111112], (2, 1, 4): [1.1111111111111112, 1.1111111111111112, 1.1111111111111112, 1.1111111111111112, -5.0, 1.1111111111111112], (2, 1, 5): [-4.888888888888889, 1.1111111111111112, 1.1111111111111112, 1.1111111111111112, 1.1111111111111112, 1.1111111111111112], (2, 2, 0): [0, 0, 1.111111, 0, 0, 1.0], (2, 2, 1): [-4.995, 0, 0, 0, 0, 1.111111111], (2, 2, 2): [0, 0, 0, 0, 0, 0], (2, 2, 3): [0, 0, 0, 0, 0, 0], (2, 2, 4): [0, 0, 0, 0, 0, 0], (2, 2, 5): [-4.8885001995899415, -4.9995, 1.11111111, 1.11111111, 1.11, 1.1111111111111112], (2, 3, 0): [0, 0, 0, 0, 1.111111, 0], (2, 3, 1): [-4.5, 0, 1.1111111111111112, 0, 0, 0], (2, 3, 2): [0, 0, 0, 0, 0, 0], (2, 3, 3): [0, 0, 0, 0, 0, 0], (2, 3, 4): [0, 0, 0, 0, 0, 0], (2, 3, 5): [-4.8888888884038, -4.995, 1.0, 1.10997548728911, 1.1111111111111112, 1.0], (2, 4, 0): [1.110980989155546, -4.840000000000001, 1.11, 1.1111111111111112, 0, 1.099989], (2, 4, 1): [-4.5, 0, 1.1, 0.99639, 0, 1.1111111111111083], (2, 4, 2): [0, 0, 0, 0, 0, 0], (2, 4, 3): [0, 0, 0, 0, 0, 0], (2, 4, 4): [0, 0, 0, 0, 0, 0], (2, 4, 5): [-4.888885, -4.99999995, 1.1111111111111112, 1.11111098979, 1.111111109999999, 1.1110999980999992], (2, 5, 0): [1.1, -4.4, 1.111, 0, -4.4, 1.1111111111111112], (2, 5, 1): [1.1111111111111112, 0, 0, 1.1099398158051057, 0, 0.9999999999999762], (2, 5, 2): [1.1111111111111112, 0, 0, 1.0999999908880098, 0, -4.95], (2, 5, 3): [1.1111111111111112, 1.0, 1.0, 0, -4.4, 0], (2, 5, 4): [1.1111111111111112, 1.11, 1.1111, 1.1110900000000001, -4.8888885, -4.9999999999949996], (2, 5, 5): [-4.888888840000001, 1.111, 1.1111111111111112, 1.111111110972, -4.888888884, 1.111111111], (3, 0, 0): [0, 0, 0, 0, 0, 0], (3, 0, 1): [0, 0, 1.11, 0, 0, 0], (3, 0, 2): [1.1111111111111, 0, 0, 0, 1.0998999999999999, -4.5], (3, 0, 3): [1.1111111111111112, 1.110999999999996, 1.1, 1.11, 1.0, -4.888400000000001], (3, 0, 4): [1.1111111111111112, 1.1111111111111112, 1.1111111111111112, 1.1111111111111112, 1.1111111111111112, -4.888888888888889], (3, 0, 5): [-4.888888888888889, 1.1111111111111112, 1.1111111111111112, 1.1111111111111112, 1.1111111111111112, -4.888888888888889], (3, 1, 0): [0, 0, 0, 0.9, 0, 0], (3, 1, 1): [0.9900000000000001, 0, 1.11, 0, 0, 0], (3, 1, 2): [1.1111111111111112, 0, 1.11, 0, 0, 0], (3, 1, 3): [1.1111111111111112, 1.1111111111110754, 1.1111111111111, 1.111111111111109, -4.9999999999995, 1.1111111110799992], (3, 1, 4): [1.1111111111111112, 1.1111111111111112, 1.1111111111111112, 1.1111111111111112, -5.0, 1.1111111111111112], (3, 1, 5): [-4.888888888888889, 1.1111111111111112, 1.1111111111111112, 1.1111111111111112, 1.1111111111111112, 1.1111111111111112], (3, 2, 0): [0, 0, 0, 0, 0, 0], (3, 2, 1): [0, 0, 0, 0, 0, 0], (3, 2, 2): [0, 0, 0, 0, 0, 0], (3, 2, 3): [0, 0, 0, 0, 0, 0], (3, 2, 4): [0, 0, 0, 0, 0, 0], (3, 2, 5): [-4.888888888888884, -4.9999999995, 1.1111111111, 1.1111111085, 1.111098897264307, 1.1111111111111112], (3, 3, 0): [0, 0, 0, 0, 1.1109999956254368, 0], (3, 3, 1): [0, 0, 0, 0, 0, 0], (3, 3, 2): [0, 0, 0, 0, 0, 0], (3, 3, 3): [0, 0, 0, 0, 0, 0], (3, 3, 4): [0, 0, 0, 0, 0, 0], (3, 3, 5): [0, 0, 1.0, 0, 1.111111111109699, 1.0], (3, 4, 0): [1.1111054019849627, -4.888400000000001, 1.111111, 1.1111111111111112, 1.111, 1.088999960628931], (3, 4, 1): [0, 0, 0, 0, 1.1111106350322262, 0], (3, 4, 2): [0, 0, 0, 0, 0, 0], (3, 4, 3): [0, 0, 0, 0, 0, 0], (3, 4, 4): [0, 0, 0, 0, 0, 0], (3, 4, 5): [-4.5, -4.5, 1.1111111111111112, 0, 0, 0], (3, 5, 0): [1.0999999763730002, -4.4, 1.1111111111111112, 1.11, -4.884, 0], (3, 5, 1): [1.1111111085933802, 0, 0, 1.0973331, -4.4000000218207695, 0], (3, 5, 2): [1.1111111110593042, 0, 1.0, 0, -4.84000453859658, 0], (3, 5, 3): [0.9999999999940027, 0, 1.1111111111110898, 0, 0, 0], (3, 5, 4): [1.1088899998575106, 1.1109980879923458, 1.111, 1.1111111111111112, -4.888840000107598, -4.995], (3, 5, 5): [-4.5, 1.11111111111, 0, 0.9, -4.8500000000100005, 0], (4, 0, 0): [0, 0, 0, 0, 0, 0], (4, 0, 1): [0, 0, 0, 0, 0, 0], (4, 0, 2): [0, 0, 0, 0, 1.1111108998958998, -4.400001900927], (4, 0, 3): [1.1111, 1.111109759541, 1.111099999999, 1.1089999999799314, 1.1111111111111112, -4.884000004036865], (4, 0, 4): [1.1111111111111112, 1.11111111111111, 1.1111111111111112, 1.1111111111111112, 1.1111111111089882, -4.888888888888889], (4, 0, 5): [-4.888888888888889, 1.1111111111111112, 1.11111111111111, 1.1111111111111098, 1.11111111111, -4.8888888888885], (4, 1, 0): [0.9, -4.5, 0, 0, 0, 0], (4, 1, 1): [0, 0, 0.9900000000000001, 0, 0, 0], (4, 1, 2): [1.11111111111, 0, 1.0, 0, 0, 0], (4, 1, 3): [1.0999999999998828, 1.1110997799990001, 1.1111, 1.111110709619998, -4.9999995, 1.1111111111111112], (4, 1, 4): [0, 0, 1.0, 1.0, -4.95, 1.1111111111111112], (4, 1, 5): [-4.888888888888889, 1.1111111111111098, 1.1111111111111112, 1.1111111111111112, 1.1111111111111112, 1.1111111111111112], (4, 2, 0): [1.1111111090687216, -4.5, 0, 0, 0, 0], (4, 2, 1): [0, 1.1111111033084635, 0, 0.9, 0.9999984923439069, 0], (4, 2, 2): [0, 0, 0, 0, 0, 0], (4, 2, 3): [0, 0, 0, 0, 0, 0], (4, 2, 4): [0, 0, 0, 0, 0, 0], (4, 2, 5): [-4.840000000000001, 0, 1.0, 0, 1.0, 1.1111111111111112], (4, 3, 0): [1.1111111111111112, -4.886900000000001, 1.098899956691824, 0.9998099280175752, 0, 1.0899999808081307], (4, 3, 1): [-4.95, 1.1111111111111112, 0, 1.0, 0.998099999995992, 0], (4, 3, 2): [0, 0, 0, 0, 0, 0], (4, 3, 3): [0, 0, 0, 0, 0, 0], (4, 3, 4): [0, 0, 0, 0, 0, 0], (4, 3, 5): [-4.840000000000001, -4.995, 1.11110899604721, 1.1111111111111112, 1.107899999999811, 1.0999999999], (4, 4, 0): [1.0898099999995992, -4.4, 1.1, 1.110899943523353, 1.1111111111111112, 0.9], (4, 4, 1): [0, 0, 0, 0, 0, 1.1108999999995548], (4, 4, 2): [0, 0, 0, 0, 0, 0], (4, 4, 3): [0, 0, 0, 0, 0, 0], (4, 4, 4): [0, 0, 0, 0, 0, 0], (4, 4, 5): [-4.5, -4.5, 1.10999999999989, 0, 0, 0], (4, 5, 0): [0.9, -4.400000005703434, 1.1111111111111112, 0.9, -4.840000000000489, 1.109999999999998], (4, 5, 1): [0.9, 0, 0, 1.09449, 0, 0], (4, 5, 2): [0, 0, 0, 0, 0, -4.5], (4, 5, 3): [0, 0, 0, 0, 0, -4.5], (4, 5, 4): [1.1097, 0.9, 1.1111111111111112, 0, -4.4, -4.9995], (4, 5, 5): [-4.5, 1.111, 0, 0, 0, 0], (5, 0, 0): [0, 0, 0, 0, 0, 0], (5, 0, 1): [0, 0, 0, 0, 0, 0], (5, 0, 2): [0, 0, 0, 0, 0, 0], (5, 0, 3): [1.0, 0, 0, 0, 1.1111111111099963, -4.400010034388291], (5, 0, 4): [1.111111111109, 1.1111111107280855, 1.1111111, -4.888888888888885, 1.1111111111111112, -4.88888888884], (5, 0, 5): [-4.4, 0, 0, 0, 1.1111111111111112, -4.4], (5, 1, 0): [0, 0, 0, 0, 0, 0], (5, 1, 1): [0.9, 0, 0, -4.5, 0, 0], (5, 1, 2): [0, 0, 0.9900000000000001, 0, 0, 0], (5, 1, 3): [1.1111111111111112, 0, 1.0, -4.5, 0, 0], (5, 1, 4): [1.1111111111111112, 1.1111111109981, 1.1111110998817173, -4.88888885361, 1.1111111111110847, 1.111111], (5, 1, 5): [-4.888888888888889, 1.1111111111110001, 1.1111111111111112, -4.888888888888889, 1.1111111111111112, 1.1111111111111112], (5, 2, 0): [0, 0, 0, 0, 0, 0], (5, 2, 1): [0, 0, 0, 0, 0, 0.9], (5, 2, 2): [0, 0, 0, 0, 0, 0], (5, 2, 3): [1.1111099999988288, 0, 0, 0, 0, 0], (5, 2, 4): [0, 1.0999889999884052, -4.5, 0, 1.1111111111111112, 1.0], (5, 2, 5): [-4.5, 1.1111111111111112, 1.0, -4.5, 0, 0], (5, 3, 0): [1.110899920019528, 0, 0, -4.5, 0, 0], (5, 3, 1): [1.1111111111111112, 0.9810000000000001, 1.10998563149, -4.850000000000796, 1.09998180913069, 0], (5, 3, 2): [1.0, 1.1111111111111112, -4.95, 0, 0, 0], (5, 3, 3): [1.1111111111111112, 1.1099999999999997, -4.9995, -4.884000000058463, 1.1111089096071, 1.1106899997786546], (5, 3, 4): [1.11111, 1.1111111111111112, -4.9999999999995, -4.888884, 1.11099937940946, 1.1110999999999989], (5, 3, 5): [-4.8885000000000005, 0.9, 1.1111111111111112, -4.840000000000001, 0.9999998099999999, 1.098080883957791], (5, 4, 0): [1.1111111111111112, -4.840042470659, 1.0, -4.8885004754796295, 0, 1.0880992801758465], (5, 4, 1): [0, 1.1111111111111112, 0.9810000000000001, -4.4, 1.08639, 1.0], (5, 4, 2): [0, 0, 0, 0, 0, 0], (5, 4, 3): [1.1111109525027, 0, 0, -4.5, 0, 0], (5, 4, 4): [1.1111111109855, 0, 0, -4.843971, 0, 1.1], (5, 4, 5): [0, 0, 0, 0, 0, 1.111111111109], (5, 5, 0): [0, 0, 1.0, 0, 0, 0], (5, 5, 1): [1.10349, 0, 0, -4.5, 0, 1.0], (5, 5, 2): [1.10349, 0, 0, 0, 0, 0], (5, 5, 3): [0, 0, 0, 0, 0, 1.1070877203], (5, 5, 4): [0, 0, 0, 0, 0, 0], (5, 5, 5): [0, 0, 0, 0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "print(learner6x6.q_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a pseudo visual for what a single run thru the haunted mansion looks like - think of it like a 2d x-ray on each pair of axes.\n",
    "\n",
    "It looks like the agent is definitely avoiding the monster hot spot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [1. 1. 1. 0. 0. 0.]\n",
      " [1. 1. 0. 0. 0. 0.]\n",
      " [1. 1. 0. 0. 0. 0.]\n",
      " [1. 1. 0. 0. 0. 0.]] \n",
      "\n",
      " [[1. 1. 0. 1. 0. 0.]\n",
      " [0. 1. 1. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 1.]\n",
      " [0. 0. 0. 0. 1. 1.]\n",
      " [0. 0. 0. 0. 1. 1.]\n",
      " [0. 0. 0. 0. 0. 1.]] \n",
      "\n",
      " [[1. 1. 1. 1. 1. 1.]\n",
      " [0. 0. 0. 0. 1. 1.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "xy, xz, yz = learner6x6.run()\n",
    "print(xy, '\\n\\n', xz, '\\n\\n', yz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 0\n",
      "episode 100\n",
      "episode 200\n",
      "episode 300\n",
      "episode 400\n",
      "episode 500\n",
      "episode 600\n",
      "episode 700\n",
      "episode 800\n",
      "episode 900\n"
     ]
    }
   ],
   "source": [
    "env10x10 = Environment(size=10, hotspots=[(2,2,2,3), (4,3,5,3)])\n",
    "learner10x10 = Agent(env10x10)\n",
    "\n",
    "learner10x10.learn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 1. 1. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]] \n",
      "\n",
      " [[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]] \n",
      "\n",
      " [[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "xy, xz, yz = learner10x10.run()\n",
    "\n",
    "xy, xz, yz = learner10x10.run()\n",
    "print(learner10x10.treasure)\n",
    "print(xy, '\\n\\n', xz, '\\n\\n', yz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wow\n",
    "I'm amazed at how quickly this thing can learn. It seems that once it finds a correct path, the training speeds up significantly because each run is straight to the exit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A treasure-hunter agent\n",
    "This should be straightforward. The strength system works like this: monsters have strength between 1 and 8. The agent starts at strength 3, and gains 1 strength for every monster it defeats (and also it gets rewarded with treasure)\n",
    "\n",
    "Should be straightforward to implement; the Agent class stays mostly the same, just the rewards for certain interactions update. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreasureHunter:\n",
    "    def __init__(self, environment):\n",
    "        self.actions = [0,1,2,3,4,5]\n",
    "        self.strength = 4\n",
    "        self.treasure = 0.0\n",
    "        self.environment = environment\n",
    "        self.env_size = environment.size\n",
    "        self.final_pos = (self.environment.size-1, self.environment.size-1, self.environment.size-1)\n",
    "        self.q_table = self.make_q_table(environment)\n",
    "        \n",
    "        # treasure hunter will encounter monsters\n",
    "        self.monster_encounters = 0\n",
    "    \n",
    "    def act(self, position):\n",
    "        x, y, z = position\n",
    "        \n",
    "        # might have to change this to pick randomly\n",
    "        action = self.choose_action(position)\n",
    "        \n",
    "        # update position\n",
    "        if action == 0: # up\n",
    "            new_pos = (x,y,z+1)\n",
    "        elif action == 1: # down\n",
    "            new_pos = (x,y,z-1)\n",
    "        elif action == 2: # left\n",
    "            new_pos = (x-1,y,z)\n",
    "        elif action == 3: # right\n",
    "            new_pos = (x+1,y,z)\n",
    "        elif action == 4: # forward\n",
    "            new_pos = (x,y+1,z)\n",
    "        elif action == 5: # backward\n",
    "            new_pos = (x,y-1,z)\n",
    "        \n",
    "        new_x, new_y, new_z = new_pos\n",
    "        \n",
    "        # check if agent went off the map\n",
    "        if new_x < 0 or new_y < 0 or new_z < 0 or new_x >= self.env_size or new_y >= self.env_size or new_z >= self.env_size:\n",
    "            reward = -5\n",
    "            new_pos = position\n",
    "            return action, new_pos, reward, False\n",
    "        \n",
    "        reward = 1\n",
    "        \n",
    "        # check for monsters and simulate interaction \n",
    "        monster = self.environment.map[new_pos][1]\n",
    "        if monster:\n",
    "            self.monster_encounters += 1\n",
    "            if self.strength > monster or (self.strength == monster and np.random.uniform() <= 0.5):\n",
    "                reward = 20 * self.environment.map[new_pos][0]\n",
    "                self.treasure += reward\n",
    "                self.strength += 1\n",
    "                \n",
    "                # clear out treasure and monster\n",
    "                self.environment.map[new_pos] = [0,0]\n",
    "                \n",
    "                return action, new_pos, reward, False\n",
    "            else:\n",
    "                reward = -1\n",
    "                return action, new_pos, reward, True\n",
    "        \n",
    "        return action, new_pos, reward, False\n",
    "            \n",
    "        \n",
    "        # Function for choosing the action for the agent\n",
    "    def choose_action(self, position):\n",
    "\n",
    "        # Selection of the action - 90 % according to the epsilon == 0.9\n",
    "        # Choosing the best action\n",
    "        if np.random.uniform() < 0.9 and not (np.argmin(self.q_table[position]) == np.argmax(self.q_table[position])):\n",
    "            state_action = self.q_table[position]\n",
    "            action = np.argmax(state_action)\n",
    "        else:\n",
    "            # Choosing random action - left 10 % for choosing randomly\n",
    "            action = np.random.choice(self.actions)\n",
    "        \n",
    "        return action\n",
    "\n",
    "    \n",
    "    \n",
    "    def learn(self, episodes=1000, learning_rate=0.9):\n",
    "        \n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        # reward decay\n",
    "        self.gamma = 0.1\n",
    "        \n",
    "        # reset q table\n",
    "        self.q_table = self.make_q_table(self.environment)\n",
    "        \n",
    "        for e in range(episodes):\n",
    "            position = (0,0,0)\n",
    "            self.strength = 6\n",
    "            self.treasure = 0\n",
    "            self.monster_encounters = 0\n",
    "            \n",
    "            # reset treasure and generate new monsters\n",
    "            self.environment.regenerate_hotspots()\n",
    "            \n",
    "            if e % 100 == 0:\n",
    "                print('episode {}'.format(e))\n",
    "            while position != self.final_pos:\n",
    "                action, new_pos, reward, dead = self.act(position)\n",
    "                if new_pos == self.final_pos:\n",
    "                    #### \n",
    "                    # Treasure hunter values exiting less\n",
    "                    ####\n",
    "                    self.q_table[position][action] += 2\n",
    "                else:\n",
    "                    self.q_table[position][action] += learning_rate * ((reward + self.gamma * max(self.q_table[new_pos]) - self.q_table[position][action]))\n",
    "                # print(learning_rate, reward, self.gamma, max(self.q_table[new_pos]))\n",
    "                if dead:\n",
    "                    position = (0,0,0)\n",
    "                    break\n",
    "                \n",
    "                position = new_pos\n",
    "                \n",
    "    def run(self):\n",
    "        xy_run = np.zeros((self.env_size, self.env_size))\n",
    "        xz_run = np.zeros((self.env_size, self.env_size))\n",
    "        yz_run = np.zeros((self.env_size, self.env_size))\n",
    "        \n",
    "        xy_run[0,0] = 1\n",
    "        xz_run[0,0] = 1\n",
    "        yz_run[0,0] = 1\n",
    "        \n",
    "        position = (0,0,0)\n",
    "        self.strength = 6\n",
    "        self.treasure = 0\n",
    "        self.monster_encounters = 0\n",
    "\n",
    "        while position != self.final_pos:\n",
    "            action, new_pos, reward, dead = self.act(position)\n",
    "            # self.q_table[position][action] += reward\n",
    "            \n",
    "            x, y, z = new_pos\n",
    "            xy_run[x,y] = 1\n",
    "            xz_run[x,z] = 1\n",
    "            yz_run[y,z] = 1\n",
    "\n",
    "            if dead:\n",
    "                position = (0,0,0)\n",
    "                break\n",
    "                \n",
    "            position = new_pos\n",
    "        \n",
    "        return xy_run, xz_run, yz_run\n",
    "            \n",
    "    \n",
    "    # the q table is a dictionary containing the reward at each \n",
    "    # position in the environment\n",
    "    def make_q_table(self, environment):\n",
    "        \n",
    "        q_table = dict()\n",
    "        width, height, depth, size = environment.map.shape\n",
    "        \n",
    "        for i in range(width):\n",
    "            for j in range(height):\n",
    "                for k in range(depth):\n",
    "                    # index:action\n",
    "                    # 0:up, 1:down, 2:left, 3:right, 4:fwd, 5:bkwd\n",
    "                    q_table[(i, j, k)] = [0,0,0,0,0,0]\n",
    "        \n",
    "        return q_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 0\n",
      "episode 100\n",
      "episode 200\n",
      "episode 300\n",
      "episode 400\n",
      "episode 500\n",
      "episode 600\n",
      "episode 700\n",
      "episode 800\n",
      "episode 900\n"
     ]
    }
   ],
   "source": [
    "env9 = Environment(size=9, hotspots=[(3,4,5,3), (1,4,1,3), (2,6,6,3)])\n",
    "\n",
    "th9 = TreasureHunter(env9)\n",
    "th9.learn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A bad run\n",
    "Monster hunting is treacherous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "monter encounters:  1\n",
      "0\n",
      "[[1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]] \n",
      "\n",
      " [[1. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 1. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]] \n",
      "\n",
      " [[1. 1. 1. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "xy, xz, yz = th9.run()\n",
    "\n",
    "print('monter encounters: ', th9.monster_encounters)\n",
    "print(th9.treasure)\n",
    "print(xy, '\\n\\n', xz, '\\n\\n', yz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A good run\n",
    "\n",
    "Here's a good run, the treasure hunter was able to gain its strength and venture to the monsters' lairs and defeat them and gather some treasure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "monter encounters:  26\n",
      "5586.758516705193\n",
      "[[1. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 0. 1. 1. 1. 1. 1.]\n",
      " [0. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 1. 1. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 1. 1.]] \n",
      "\n",
      " [[1. 1. 1. 0. 0. 1. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 1. 1. 1. 1. 0.]\n",
      " [0. 0. 1. 1. 1. 1. 1. 1. 0.]\n",
      " [0. 0. 1. 1. 1. 1. 1. 0. 0.]\n",
      " [0. 1. 1. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 1. 1. 1. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 1. 1.]] \n",
      "\n",
      " [[1. 1. 1. 1. 1. 1. 0. 0. 0.]\n",
      " [0. 1. 1. 1. 1. 1. 0. 0. 0.]\n",
      " [0. 1. 1. 1. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 1. 1. 0.]\n",
      " [0. 0. 1. 1. 1. 1. 1. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 1. 1. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "xy, xz, yz = th9.run()\n",
    "\n",
    "print('monter encounters: ', th9.monster_encounters)\n",
    "print(th9.treasure)\n",
    "print(xy, '\\n\\n', xz, '\\n\\n', yz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "env20 = Environment(size=20, hotspots=[(3,4,5,3), (2,4,2,3), (2,6,6,3), (10,12,4,5), (5,16,9,3)])\n",
    "agent20 = TreasureHunter(env20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 0\n",
      "episode 100\n",
      "episode 200\n",
      "episode 300\n",
      "episode 400\n",
      "episode 500\n",
      "episode 600\n",
      "episode 700\n",
      "episode 800\n",
      "episode 900\n",
      "episode 1000\n",
      "episode 1100\n",
      "episode 1200\n",
      "episode 1300\n",
      "episode 1400\n",
      "episode 1500\n",
      "episode 1600\n",
      "episode 1700\n",
      "episode 1800\n",
      "episode 1900\n",
      "episode 2000\n",
      "episode 2100\n",
      "episode 2200\n",
      "episode 2300\n",
      "episode 2400\n"
     ]
    }
   ],
   "source": [
    "agent20.learn(episodes=2500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "monter encounters:  227\n",
      "44335.55296750015\n",
      "[[1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]] \n",
      "\n",
      " [[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]] \n",
      "\n",
      " [[1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 1. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "xy, xz, yz = agent20.run()\n",
    "\n",
    "print('monter encounters: ', agent20.monster_encounters)\n",
    "print(agent20.treasure)\n",
    "print(xy, '\\n\\n', xz, '\\n\\n', yz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nice! \n",
    "There were 233 monsters possible, so that run got close to killing them all and collecting *all* the treasure. This monster hunter is pretty good!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learning",
   "language": "python",
   "name": "learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
