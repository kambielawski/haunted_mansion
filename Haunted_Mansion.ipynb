{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Haunted Mansion\n",
    "\n",
    "Welcome to the haunted mansion, a 3 dimensional array for an agent to learn to navigate. The agent will start out in position (0,0,0) and it will try to exit at point (size,size,size). I will start with a relatively small size and adjust it if needed.\n",
    "\n",
    "### The agent will encounter a few things throughout its journey through the haunted mansion. \n",
    "- It will encounter monsters sporadically\n",
    "    - There will be \"hot spots\", maybe 3x3x3 areas where monsters are likely to spawn, and in the center of themis lots of treasure. \n",
    "    \n",
    "- It will encounter treasure throughout its adventure\n",
    "    - The treasure will be the *value* metric of the agent. The immediate reward will be the steps that it takes. \n",
    "    \n",
    "\n",
    "### Two policies\n",
    "1. We'll try to design a policy where the agent wants to get *out* of the haunted mansion as quickly as it can. \n",
    "\n",
    "2. We'll also try a \"hero\" policy where it collects as much treasure as it can and gains strength (through slaying monsters) \n",
    "\n",
    "### Strength\n",
    "The agent will have a strength that determines whether it will die or win against a given monster. The monsters will spawn probabilistically in a given \"hot spot\" and they will have strengths as well. If the agent wins (ie. agent strength > monster strength), it gains strength. If they are equally matched, it is a coin flip. \n",
    "\n",
    "### Treasure \n",
    "Treasure will be the value function of the environment. There will be more treasure available inside of the monster zones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's first set up the environment and the agent\n",
    "\n",
    "# importing scipy.stats for normal distribution for monster spawning probabilities\n",
    "import scipy.stats\n",
    "\n",
    "tre = 0\n",
    "mon = 1\n",
    "\n",
    "class Environment: \n",
    "    def __init__(self, size):\n",
    "        self.hotspot_prob_cache3x3 = self.gen_hotspot_prob_matrix(3)\n",
    "        self.hotspot_prob_cache5x5 = self.gen_hotspot_prob_matrix(5)\n",
    "        self.map = self.generate_map(size, hotspots=[(size//2, size//2, size//2, 3)])\n",
    "        \n",
    "    def generate_map(self, map_size, hotspots):\n",
    "        env = np.empty(shape=(map_size, map_size, map_size, 2))\n",
    "        \n",
    "        for i in range(map_size):\n",
    "            for j in range(map_size):\n",
    "                for k in range(map_size):\n",
    "                    treasure = 0\n",
    "                    monster = None\n",
    "                    env[i,j,k] = [treasure, monster]\n",
    "                    \n",
    "        for (x, y, z, s) in hotspots:\n",
    "            r = s // 2\n",
    "            env[x-r:x+r+1, y-r:y+r+1, z-r:z+r+1] = self.populate_hotspot((x, y, z), s)\n",
    "        \n",
    "        return env\n",
    "            \n",
    "            \n",
    "    def populate_hotspot(self, loc, hotspot_size):\n",
    "        r = hotspot_size // 2\n",
    "        x, y, z = loc\n",
    "        \n",
    "        hotspot = np.empty(shape=(hotspot_size, hotspot_size, hotspot_size, 2))\n",
    "        \n",
    "        for i in range(hotspot_size):\n",
    "            for j in range(hotspot_size):\n",
    "                for k in range(hotspot_size):\n",
    "                    # treasure is multiplied by the probability of a monster\n",
    "                    treasure = self.hotspot_prob_cache3x3[i,j,k] * 10\n",
    "                    monster = np.random.randint(8)+1       # random strength 1 to 8\n",
    "                    hotspot[i,j,k] = [treasure, monster]\n",
    "        \n",
    "        return hotspot\n",
    "        \n",
    "        \n",
    "    \n",
    "    # the distance from the center of the hotspot determines\n",
    "    # how likely a monster is to spawn there - there is always\n",
    "    # a monster in the center\n",
    "    def gen_hotspot_prob_matrix(self, size):\n",
    "        \n",
    "        arr = np.zeros((size,size,size))\n",
    "        mid = (size//2, size//2, size//2)\n",
    "        xh, yh, zh = mid\n",
    "        \n",
    "        # generate probabilities at given relative locations\n",
    "        for i in range(size):\n",
    "            for j in range(size):\n",
    "                for k in range(size):\n",
    "                    dist = np.sqrt((i-xh)**2 + (j-yh)**2 + (k-zh)**2)\n",
    "                    gen_prob = scipy.stats.norm(0, size/2).cdf(-dist)\n",
    "                    arr[i,j,k] = gen_prob\n",
    "        \n",
    "        # always a monster in the center!\n",
    "        arr[mid] = 1\n",
    "                    \n",
    "        return arr\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.12410654 0.17288929 0.12410654]\n",
      "  [0.17288929 0.25249254 0.17288929]\n",
      "  [0.12410654 0.17288929 0.12410654]]\n",
      "\n",
      " [[0.17288929 0.25249254 0.17288929]\n",
      "  [0.25249254 1.         0.25249254]\n",
      "  [0.17288929 0.25249254 0.17288929]]\n",
      "\n",
      " [[0.12410654 0.17288929 0.12410654]\n",
      "  [0.17288929 0.25249254 0.17288929]\n",
      "  [0.12410654 0.17288929 0.12410654]]]\n"
     ]
    }
   ],
   "source": [
    "env = Environment(6)\n",
    "\n",
    "# here's the probability of a monster spawning in a given 3x3x3 hotspot\n",
    "# note there will always be a monster in the middle of the hotspot\n",
    "# (this is where the most treasure is!)\n",
    "print(env.hotspot_prob_cache3x3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[nan nan nan nan nan nan]\n",
      "  [nan nan nan nan nan nan]\n",
      "  [nan nan nan nan nan nan]\n",
      "  [nan nan nan nan nan nan]\n",
      "  [nan nan nan nan nan nan]\n",
      "  [nan nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan nan]\n",
      "  [nan nan nan nan nan nan]\n",
      "  [nan nan nan nan nan nan]\n",
      "  [nan nan nan nan nan nan]\n",
      "  [nan nan nan nan nan nan]\n",
      "  [nan nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan nan]\n",
      "  [nan nan nan nan nan nan]\n",
      "  [nan nan  3.  4.  5. nan]\n",
      "  [nan nan  2.  4.  1. nan]\n",
      "  [nan nan  6.  2.  6. nan]\n",
      "  [nan nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan nan]\n",
      "  [nan nan nan nan nan nan]\n",
      "  [nan nan  1.  2.  4. nan]\n",
      "  [nan nan  5.  3.  3. nan]\n",
      "  [nan nan  4.  4.  8. nan]\n",
      "  [nan nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan nan]\n",
      "  [nan nan nan nan nan nan]\n",
      "  [nan nan  5.  8.  3. nan]\n",
      "  [nan nan  6.  3.  1. nan]\n",
      "  [nan nan  7.  5.  7. nan]\n",
      "  [nan nan nan nan nan nan]]\n",
      "\n",
      " [[nan nan nan nan nan nan]\n",
      "  [nan nan nan nan nan nan]\n",
      "  [nan nan nan nan nan nan]\n",
      "  [nan nan nan nan nan nan]\n",
      "  [nan nan nan nan nan nan]\n",
      "  [nan nan nan nan nan nan]]]\n"
     ]
    }
   ],
   "source": [
    "# and here we can see the \"hot spot\" on a small map\n",
    "# the numbers are the strengths of the monsters in that area\n",
    "print(env.map[:,:,:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent\n",
    "Now we have to design an agent.\n",
    "\n",
    "An agent has actions that respond to the environment. The actions here will be up, down, left, right, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self):\n",
    "        self.strength = 1\n",
    "        self.treasure = 0.0\n",
    "        self.actions = ['U', 'D', 'L', 'R', 'F', 'B']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl",
   "language": "python",
   "name": "rl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
